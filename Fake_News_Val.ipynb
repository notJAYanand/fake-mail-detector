{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake News Val.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "R_K9SJQ389R4"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/fake news/resources/fake_news2.h5')"
      ],
      "metadata": {
        "id": "S0cICJS99YEf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/fake news/resources/val.csv')"
      ],
      "metadata": {
        "id": "EKD_ci-o9i22"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val= testset.iloc[:,:-1].values\n",
        "y_val= testset.iloc[:,-1].values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y1_val=le.fit_transform(y_val)"
      ],
      "metadata": {
        "id": "EwKT3OKW9rno"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX292pGp-aqn",
        "outputId": "bda84803-377f-46bf-c557-c727e37a4849"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        " #stop words the,a etc\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer #stemming simplifies words eg loved->love minimising dimension of the sparse matrix\n",
        "corpus = []\n",
        "for i in range(0, len(testset)):  # NTS last me change kar lena range\n",
        "  review= re.sub('[^a-zA-Z]', ' ', testset['text'][i])    # ^ == NOT\n",
        "  review= review.lower()\n",
        "  review= review.split()\n",
        "  #ps=PorterStemmer()\n",
        "  all_stopwords=stopwords.words('english')\n",
        "  all_stopwords.remove('not') # NTS stopword aur customize as per req\n",
        "  review=[lemmatizer.lemmatize(word) for word in review if not word in set(all_stopwords)] #apply steming to all words except stopwords\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_zGjKqU-Bt8",
        "outputId": "6c426259-190f-4440-deb6-2953b40d6d6b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "voc_size=5000\n",
        "res=[one_hot(words,voc_size)for words in corpus] "
      ],
      "metadata": {
        "id": "7jqqM0D6p1tm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "lb-A-fuP-10X"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= testset.iloc[:,:-1].values\n",
        "temp=0\n",
        "max=0\n",
        "for i in x:\n",
        "  temp=0\n",
        "  j=str(i)\n",
        "  for words in j.split(' '):\n",
        "    temp+=1\n",
        "\n",
        "  if temp>max:\n",
        "    max=temp\n",
        "print(max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SQNvDQq-9-M",
        "outputId": "5ca5ff91-38c4-4e3f-bf83-792085d656ef"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "sent=98\n",
        "embedded=pad_sequences(res,padding='pre',maxlen=sent)\n",
        "print(embedded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kepu8Ui-4en",
        "outputId": "bf28fb4a-4089-4bfe-eec9-b575b942c1e3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ... 1407 4487 3761]\n",
            " [   0    0    0 ... 1798 1964 2915]\n",
            " [   0    0    0 ... 2876 4984 1204]\n",
            " ...\n",
            " [   0    0    0 ... 3752 3359  930]\n",
            " [   0    0    0 ... 1964 4210 1832]\n",
            " [   0    0    0 ... 3101  892 4917]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred=model.predict(embedded)\n",
        "\n",
        "y_pred=model.predict_classes( embedded, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "5SiCSFa__FCb",
        "outputId": "8228388b-e698-4826-e9b6-2fcad5424cd4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-493dee864294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# y_pred=model.predict(embedded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for i in range(0,len(y_pred)):\n",
        "#   if(y_pred[i]>=0.50):\n",
        "#     y_pred[i]=1\n",
        "#   else:\n",
        "#     y_pred[i]=0"
      ],
      "metadata": {
        "id": "G-E-SyyK_KKU"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pr_text=[]\n",
        "# for i in range(0,len(y_pred)):\n",
        "#   if(y_pred[i]==1.0):\n",
        "#     y_pr_text.append('real')\n",
        "#   else:\n",
        "#     y_pr_text.append('fake')"
      ],
      "metadata": {
        "id": "DzcWbW0qKFx8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y1_val, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y1_val, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWpGdCSk_MH1",
        "outputId": "983a6460-c45a-4d5a-e58f-30bbf8189070"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  114 11094]\n",
            " [  300 27158]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7053225055604407"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# prediction = pd.DataFrame(y_pr_text, columns=['label']).to_csv('/content/drive/MyDrive/Colab Notebooks/fake news/resources/prediction2.csv')"
      ],
      "metadata": {
        "id": "R894oeUs_O38"
      },
      "execution_count": 63,
      "outputs": []
    }
  ]
}